{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c24da773",
   "metadata": {},
   "source": [
    "# 任务一：音频预处理\n",
    "本题主要考察考生对音频数据预处理流程的理解和实现能力。需要完成以下任务：\n",
    "- 读取音频文件，转换为16kHz采样率的单声道音频。\n",
    "- 对音频进行归一化处理，确保音频的振幅在[-1, 1]范围内。\n",
    "- 对音频进行 FFT 变换，提取频域特征并输出频谱图。\n",
    "- 对音频进行短时傅里叶变换（STFT），提取时域特征并输出时频图。\n",
    "- 输出音频梅尔频谱图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b2ab61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librosa version: 0.10.2.post1\n"
     ]
    }
   ],
   "source": [
    "# TODO: 添加必要的库\n",
    "import librosa\n",
    "print(\"Librosa version:\", librosa.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee69346d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_636404/2353551125.py:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load('./data/sample_recording.wav', sr=16000, mono=True)\n",
      "/home/whao/Developer/2025-Anhui-AI-Speech-Technology-Competition/.venv/lib/python3.12/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/sample_recording.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLibsndfileError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/2025-Anhui-AI-Speech-Technology-Competition/.venv/lib/python3.12/site-packages/librosa/core/audio.py:176\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     y, sr_native = \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m sf.SoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    179\u001b[39m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/2025-Anhui-AI-Speech-Technology-Competition/.venv/lib/python3.12/site-packages/librosa/core/audio.py:209\u001b[39m, in \u001b[36m__soundfile_load\u001b[39m\u001b[34m(path, offset, duration, dtype)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    208\u001b[39m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     context = \u001b[43msf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/2025-Anhui-AI-Speech-Technology-Competition/.venv/lib/python3.12/site-packages/soundfile.py:658\u001b[39m, in \u001b[36mSoundFile.__init__\u001b[39m\u001b[34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[39m\n\u001b[32m    656\u001b[39m \u001b[38;5;28mself\u001b[39m._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[32m    657\u001b[39m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[32m--> \u001b[39m\u001b[32m658\u001b[39m \u001b[38;5;28mself\u001b[39m._file = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode).issuperset(\u001b[33m'\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.seekable():\n\u001b[32m    660\u001b[39m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/2025-Anhui-AI-Speech-Technology-Competition/.venv/lib/python3.12/site-packages/soundfile.py:1216\u001b[39m, in \u001b[36mSoundFile._open\u001b[39m\u001b[34m(self, file, mode_int, closefd)\u001b[39m\n\u001b[32m   1215\u001b[39m     err = _snd.sf_error(file_ptr)\n\u001b[32m-> \u001b[39m\u001b[32m1216\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix=\u001b[33m\"\u001b[39m\u001b[33mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mself\u001b[39m.name))\n\u001b[32m   1217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode_int == _snd.SFM_WRITE:\n\u001b[32m   1218\u001b[39m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[32m   1219\u001b[39m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[32m   1220\u001b[39m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[31mLibsndfileError\u001b[39m: Error opening './data/sample_recording.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# TODO: 读取音频文件，转换为16kHz采样率的单声道音频\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 例如：`y, sr = librosa.load('./data/sample_recording.wav', sr=16000, mono=True)`\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m y, sr = \u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./data/sample_recording.wav\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmono\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/2025-Anhui-AI-Speech-Technology-Competition/.venv/lib/python3.12/site-packages/librosa/core/audio.py:184\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib.PurePath)):\n\u001b[32m    181\u001b[39m     warnings.warn(\n\u001b[32m    182\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[33m\"\u001b[39m, stacklevel=\u001b[32m2\u001b[39m\n\u001b[32m    183\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     y, sr_native = \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/2025-Anhui-AI-Speech-Technology-Competition/.venv/lib/python3.12/site-packages/decorator.py:235\u001b[39m, in \u001b[36mdecorate.<locals>.fun\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[32m    234\u001b[39m     args, kw = fix(args, kw, sig)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/2025-Anhui-AI-Speech-Technology-Competition/.venv/lib/python3.12/site-packages/librosa/util/decorators.py:59\u001b[39m, in \u001b[36mdeprecated.<locals>.__wrapper\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[32m     51\u001b[39m warnings.warn(\n\u001b[32m     52\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m     stacklevel=\u001b[32m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[32m     58\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/2025-Anhui-AI-Speech-Technology-Competition/.venv/lib/python3.12/site-packages/librosa/core/audio.py:240\u001b[39m, in \u001b[36m__audioread_load\u001b[39m\u001b[34m(path, offset, duration, dtype)\u001b[39m\n\u001b[32m    237\u001b[39m     reader = path\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     reader = \u001b[43maudioread\u001b[49m\u001b[43m.\u001b[49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[32m    243\u001b[39m     sr_native = input_file.samplerate\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/2025-Anhui-AI-Speech-Technology-Competition/.venv/lib/python3.12/site-packages/audioread/__init__.py:127\u001b[39m, in \u001b[36maudio_open\u001b[39m\u001b[34m(path, backends)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[32m    129\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/2025-Anhui-AI-Speech-Technology-Competition/.venv/lib/python3.12/site-packages/audioread/rawread.py:59\u001b[39m, in \u001b[36mRawAudioFile.__init__\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28mself\u001b[39m._fh = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m         \u001b[38;5;28mself\u001b[39m._file = aifc.open(\u001b[38;5;28mself\u001b[39m._fh)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './data/sample_recording.wav'"
     ]
    }
   ],
   "source": [
    "# TODO: 读取音频文件，转换为16kHz采样率的单声道音频\n",
    "# 例如：`y, sr = librosa.load('./data/sample_recording.wav', sr=16000, mono=True)`\n",
    "y, sr = librosa.load('./data/sample_recording.wav', sr=16000, mono=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2813b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:输出 FFT 频域频谱图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83380469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 输出短时傅里叶变换（STFT）时频图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0530d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 输出 Mel 频谱图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a686c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "ANSWER: dict = {\n",
    "    'b8df9c6e1e0671400c88bf76ea9b01ee5198f9e077a2b6d05d62ee5eb1926d71': 'fear',\n",
    "    'c9ae526d0cad6a7a992d515a28d23992bd08052e4067f52e51f763864281b215': 'fear',\n",
    "    'd6d1628785d457c0e9b581ce65e650f732e06523dda07d58083d2bbd0959a2f5': 'fear',\n",
    "    '06b0bfc5df3c191e00a255fb09dc3c138ad242be312627d19552be534f0db957': 'fear',\n",
    "    '3d84b486ec8ef356f0fedc1bc7c1682d6a8b6c505ef2c10efe52a35ff4f7bec5': 'fear',\n",
    "    '529fe47c444f0d09d3666b44c1d670e27bac39df7e39b7ee0110252dde3888f2': 'fear',\n",
    "    'e31741f705fee11a233e759af986e4878d0c07a53c8596b86c8843c9b0def45e': 'fear',\n",
    "    'ec843200bd063e27a6826611e5da281c28c663fa807de8ffa1ed89fcb58b7666': 'fear',\n",
    "    '91803fad54309abc8d5891d1099091a857b5ea33250ba51ed03e4cd74562ea54': 'fear',\n",
    "    '90efe02f47ad34469b430fdf85dfa2fe7eb45408d447fabc0a80428c8e62f161': 'fear',\n",
    "    '4d594588ca878e05cf804d88c27212d117b6dc48197c8ef88564ceb00bb2fff1': 'sad',\n",
    "    'c8b3a5b86806b0ef9ecc54cda5632f14e1b392bd9906ee082620ba8ebadc7da9': 'sad',\n",
    "    '91ee6703651ba441bf64f6556566915a84b4ba679ef3e1d02b271c7359288fee': 'sad',\n",
    "    'bbe6b21e872dde394f633c713dc009acf7d2fa89e286212e3b7086d91b792d52': 'sad',\n",
    "    'e343040049e7e799f0e087a53e8262e176c18e9df63c17fe9d36c4d90dec7ae1': 'sad',\n",
    "    '685092119b8bd62b697eaf04e2bbf8f25ec73538eeac02a854ff32b74c2a3f61': 'sad',\n",
    "    '1b5cd63fd6738db3a95ac7dbacf962148094b1f7c37a3a0e55af42a3979f38aa': 'sad',\n",
    "    '056fb0e64a845cd000e56e7dce460d806064de7a44b3e4f593f4126af4612dfa': 'sad',\n",
    "    'f0c53ca61815b2e12eb39c0e1042ffad6b6489ff0e9b16acfc210d8cf1c1b207': 'sad',\n",
    "    '64386c9f38edac0929eaec61eb84755e5fbf642df920b5397299b1a931e59124': 'sad',\n",
    "    'f2ba0187d76338363133c30abde84c231c3939edd0284375e703a5a1993b6f6f': 'surprise',\n",
    "    'efbfd06cc06bfa75fba85af3cb7e69469d87944f4864039276b9807f6c092181': 'surprise',\n",
    "    '9625017b7688df5d9dfac71f0a642c1c3e7b4e01c4706f11cb7c3f344573da1f': 'surprise',\n",
    "    '69ad9fd8a68e3b7ec42c7b7d0bf93c3efb13c66d748f3023d02bddbd57a98bfe': 'surprise',\n",
    "    '57890963bad9b9ca2d538edb4f9e2fcec397886bc25e20a1b42aff67979f98ee': 'surprise',\n",
    "    'a91a6da34edb5d3c4b638e837568842bf4c4d0059f7505f85e43f520b1e283ef': 'surprise',\n",
    "    '3b51df12c63a62a02899e3e66f227882bffcfe485b0ce9d93ccd1ca79b86bb11': 'surprise',\n",
    "    'c0b9c8f9a62a6084b83f9e15204ee2772a48be9f0c030b2f2d760d5abf22aa52': 'surprise',\n",
    "    '6b724f984a8e1f4576da7c0c174730941fb0fad824154fa4b1058eaa5803b113': 'surprise',\n",
    "    '01186ea5bd9e0a6e7915a14d0072408d593f3bffa1a3b56aba6ab508bb16c2f9': 'surprise',\n",
    "    '724442095b6b328189d72cff58740b1416a8ee0799d55a3e81aefa21778006cb': 'neutral',\n",
    "    '4a8897b3f6414a54022a7dc86798282fff119ce26aeec2f46306667af8d8e7cb': 'neutral',\n",
    "    'b7ec2a8ccc2b9b1a156727b013009c2e0d03e25220080daa501f9605c62e5549': 'neutral',\n",
    "    '313ffac918f8f28ad28524f19a8b5b8e0b44216166828c2c5e0f354179138ac1': 'neutral',\n",
    "    '0f77af89e30a943eb64c9e1c888f03043519e5c5516be02b78c1bd8619dfc4a9': 'neutral',\n",
    "    '33eab11c55244374722cf98a7ccb6dbe9860718985bd32209c7909a9f3fe01d0': 'neutral',\n",
    "    '04da1b7a8652b9266449328b1c8b931bb9f10e60c5793bd99fbdf53920024164': 'neutral',\n",
    "    '1e86b29c591a686dc3486073b2a7d1a396c1761a1b4379957b49350744fdc052': 'neutral',\n",
    "    '709f73148c4d869a94b316899b990fa95118783f65b32b4c24b0b9750ebe5086': 'neutral',\n",
    "    '498f9c327b1f4f8569db43c0ba437c4ffa32125f5fecd61aef697d82023f81e5': 'neutral',\n",
    "    'a6c418db78ecfd8c74ff699d2cb4f448eb2291104283c69f5808dabc1a33692d': 'angry',\n",
    "    '5c73defa2ee22f4e4173b4f583d51b42b4aa4bfbb1af3a1fa65f89e80cf51434': 'angry',\n",
    "    '21d7820ef1df77c743057ab1a2cda474ef13798927148cc6cb8d4aa678577e9f': 'angry',\n",
    "    '8b9581c9232fe4a45f31b4cea5287647907d19bc1a743d9e8b514eb10b2a74a1': 'angry',\n",
    "    '5965fa6d783a2bef249e68682322b10b7ec569da74c654c0993687c75a18e10d': 'angry',\n",
    "    '64c05c9ef7eba192b151ad4ad9be352c1f0cfee0398ebb5d088a3752a4e21220': 'angry',\n",
    "    '44ca8e83f257ba098274a64e41f4526182bb43838de73f5bf6a93c01eed69754': 'angry',\n",
    "    '4cccdeeeed197091f1488a01e7f49e348cac3a26764c09939f89905172873162': 'angry',\n",
    "    '5df924d2afc2548833776a7f881e1b50f78bc58cc89b695dbdc8bfa8935ecb81': 'angry',\n",
    "    'f99d61c98008c830fc4db1b61ee10b33b30bb96d66109ed71719cd5a1dd5f87c': 'angry',\n",
    "    '6539e0492498a3b621e91c4cc16dcde03c7f8510be88c4df2589d879a47d0156': 'happy',\n",
    "    'b5f1487ccbba22f38b429d4fb753680acc6570d3f6c723c0eb6509fe10be351a': 'happy',\n",
    "    '9777e4e495fda9a0d0eea09eab060ce653634ec45dd2213286cca52584b95d70': 'happy',\n",
    "    '363e0bea5a22d76f01c0665ef26f8daf22cc3c38fdfc213a318a4752deb7c7b4': 'happy',\n",
    "    '20195b018a6155e3a612b981bc1ebddadfc00f730c9c98bd88978916b2d2c55c': 'happy',\n",
    "    'f331137029e95e96b6e18123f9626e2b66b8f5e1d04330af0234b9651cc45c25': 'happy',\n",
    "    '8273ba9fbf46443129d36f9df410608c1beea6f5edeeaf6f340ccec71dcf5d8c': 'happy',\n",
    "    'b39e0870be8590889d4192665bd247ddc85f32fc22032274941781d7f94a191a': 'happy',\n",
    "    '2dcc0cd3c9f87e76b8f3add5f0bdab671c14c456900141f611b7030c6443ef12': 'happy',\n",
    "    'f9587ad0aef671f2ac947f3a6e648bb2823657ec13f440a1f0a5783e03aa45fd': 'happy',\n",
    "}\n",
    "json.dump(ANSWER, open(\"task-3-answer.json\", \"w\"), indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2025-Anhui-AI-Speech-Technology-Competition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
